{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57dec2d-d55f-452f-87a4-abfeedf1de27",
   "metadata": {},
   "source": [
    "# L5: Instruction Tuning and Guardrails\n",
    "\n",
    "In this lesson, you'll take everything you've learned from previous lessons and add advanced control mechanisms that transform your agents from helpful assistants into specialized, production-ready systems.\n",
    "\n",
    "### Building on previous lessons\n",
    "\n",
    "So far in this course, you've built:\n",
    "\n",
    "- **Lesson 1**: Basic agents with Google search capabilities\n",
    "- **Lesson 2**: Session, State & Memory in agents\n",
    "- **Lesson 3**: Interactive chat agents with financial data integration (`get_financial_context`)  \n",
    "- **Lesson 4**: Coordinator agents with file persistence (`save_news_to_markdown`) and structured workflows\n",
    "\n",
    "### What's new in Lesson 5\n",
    "\n",
    "Now you'll add another piece: **programmatic control systems** to ensure your agents behave reliably in production environments:\n",
    "\n",
    "- **Callback Systems**: Programmatic guardrails that automatically enforce policies\n",
    "    1. **Domain Filtering**: Before Tool callback that blocks certain sources thus controlling information access\n",
    "    2. **Response Enhancement**: After Tool callback that adds transparency and audit trails into agent outputs\n",
    "- **Update agent's instructions**: We'll update the agent's instructions to make it callback-aware.\n",
    "\n",
    "By the end of this lesson, you'll have a production-ready agent that uses all the tools from previous lessons but with effective control mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51478044-cc86-4ef9-b82b-b5217c848a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c3d9a-4032-498c-bce9-e4c585517690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create our expected agent folder \n",
    "# You can explore available option: !adk create --help \n",
    "\n",
    "!adk create --type=code app5 --model gemini-2.0-flash-live-001 --api_key $GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ba2bf-1de7-4170-9cdd-1f378071b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app5/agent.py\n",
    "import pathlib\n",
    "from typing import Dict, List\n",
    "import yfinance as yf\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "\n",
    "def get_financial_context(tickers: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fetches the current stock price and daily change for a list of stock tickers\n",
    "    using the yfinance library.  \n",
    "\n",
    "    Args:\n",
    "        tickers: A list of stock market tickers (e.g., [\"NVDA\", \"MSFT\"]).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping each ticker to its formatted financial data string.\n",
    "    \"\"\"\n",
    "    financial_data: Dict[str, str] = {}\n",
    "    for ticker_symbol in tickers:\n",
    "        try:\n",
    "            # Create a Ticker object\n",
    "            stock = yf.Ticker(ticker_symbol)\n",
    "            \n",
    "            # Fetch the info dictionary\n",
    "            info = stock.info\n",
    "            \n",
    "            # Safely access the required data points\n",
    "            price = info.get(\"currentPrice\") or info.get(\"regularMarketPrice\")\n",
    "            change_percent = info.get(\"regularMarketChangePercent\")\n",
    "            \n",
    "            if price is not None and change_percent is not None:\n",
    "                # Format the percentage and the final string\n",
    "                change_str = f\"{change_percent * 100:+.2f}%\"\n",
    "                financial_data[ticker_symbol] = f\"\\${price:.2f} ({change_str})\"\n",
    "            else:\n",
    "                # Handle cases where the ticker is valid but data is missing\n",
    "                financial_data[ticker_symbol] = \"Price data not available.\"\n",
    "\n",
    "        except Exception:\n",
    "            # This handles invalid tickers or other yfinance errors gracefully\n",
    "            financial_data[ticker_symbol] = \"Invalid Ticker or Data Error\"\n",
    "            \n",
    "    return financial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152b002-4ddb-4b1b-8e45-d7b2ad2f028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "def save_news_to_markdown(filename: str, content: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Saves the given content to a Markdown file in the current directory.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file to save (e.g., 'ai_news.md').\n",
    "        content: The Markdown-formatted string to write to the file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the status of the operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not filename.endswith(\".md\"):\n",
    "            filename += \".md\"\n",
    "        current_directory = pathlib.Path.cwd()\n",
    "        file_path = current_directory / filename\n",
    "        file_path.write_text(content, encoding=\"utf-8\")\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Successfully saved news to {file_path.resolve()}\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Failed to save file: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59099f73-dc49-497c-81cb-0e5fabbdce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "BLOCKED_DOMAINS = [\n",
    "    \"wikipedia.org\",      # General info, not latest news\n",
    "    \"reddit.com\",         # Discussion forums, not primary news\n",
    "    \"youtube.com\",        # Video content not useful for text processing\n",
    "    \"medium.com\",         # Blog platform with variable quality\n",
    "    \"investopedia.com\",   # Financial definitions, not tech news\n",
    "    \"quora.com\",          # Q&A site, opinions not reports\n",
    "]\n",
    "\n",
    "def filter_news_sources_callback(tool, args, tool_context):\n",
    "    \"\"\"\n",
    "    Callback: Blocks search requests that target certain domains which are not necessarily news sources.\n",
    "    Demonstrates content quality enforcement through request blocking.\n",
    "    \"\"\"\n",
    "    if tool.name == \"google_search\":\n",
    "        query = args.get(\"query\", \"\").lower()\n",
    "\n",
    "        # Check if query explicitly targets blocked domains\n",
    "        for domain in BLOCKED_DOMAINS:\n",
    "            if f\"site:{domain}\" in query or domain.replace(\".org\", \"\").replace(\".com\", \"\") in query:\n",
    "                print(f\"BLOCKED: Domains from blocked list detected: '{query}'\")\n",
    "                return {\n",
    "                    \"error\": \"blocked_source\",\n",
    "                    \"reason\": f\"Searches targeting {domain} or similar are not allowed. Please search for professional news sources.\"\n",
    "                }\n",
    "\n",
    "        print(f\"ALLOWED: Professional source query: '{query}'\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f23d0-0c7a-4060-a13c-1c2f7d0d55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "def initialize_process_log(tool_context: ToolContext):\n",
    "    \"\"\"Helper to ensure the process_log list exists in the state.\"\"\"\n",
    "    if 'process_log' not in tool_context.state:\n",
    "        tool_context.state['process_log'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bc1e7-a88a-47ab-b155-c06220143e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "def inject_process_log_after_search(tool, args, tool_context, tool_response):\n",
    "    \"\"\"\n",
    "    Callback: After a successful search, this injects the process_log into the response\n",
    "    and adds a specific note about which domains were sourced. This makes the callbacks'\n",
    "    actions visible to the LLM.\n",
    "    \"\"\"\n",
    "    if tool.name == \"google_search\" and isinstance(tool_response, str):\n",
    "        # Extract source domains from the search results\n",
    "        urls = re.findall(r'https?://[^\\s/]+', tool_response)\n",
    "        unique_domains = sorted(list(set(urlparse(url).netloc for url in urls)))\n",
    "        \n",
    "        if unique_domains:\n",
    "            sourcing_log = f\"Action: Sourced news from the following domains: {', '.join(unique_domains)}.\"\n",
    "            # Prepend the new log to the existing one for better readability in the report\n",
    "            current_log = tool_context.state.get('process_log', [])\n",
    "            tool_context.state['process_log'] = [sourcing_log] + current_log\n",
    "\n",
    "        final_log = tool_context.state.get('process_log', [])\n",
    "        print(f\"CALLBACK LOG: Injecting process log into tool response: {final_log}\")\n",
    "        return {\n",
    "            \"search_results\": tool_response,\n",
    "            \"process_log\": final_log\n",
    "        }\n",
    "    return tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401348f-3dcd-4bb2-9c15-4a37fb8cd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"ai_news_research_coordinator\",\n",
    "    model=\"gemini-2.0-flash-live-001\",\n",
    "    tools=[google_search, get_financial_context, save_news_to_markdown],\n",
    "    instruction=\"\"\"\n",
    "    **Your Core Identity and Sole Purpose:**\n",
    "    You are a specialized AI News Assistant that creates structured podcast content. Your sole and exclusive purpose is \n",
    "    to find and summarize recent news about Artificial Intelligence and format it into comprehensive podcast outlines.\n",
    "\n",
    "    **Execution Plan:**\n",
    "\n",
    "    1.  \n",
    "        *   **Step 1:** Call `google_search` to find 5 recent AI news articles.\n",
    "        *   **Step 2:** Analyze the results to find company stock tickers.\n",
    "        *   **Step 3:** Call `get_financial_context` with the list of tickers.\n",
    "        *   **Step 4:** Format all gathered information into a single Markdown string, \n",
    "            following the **Required Report Schema**.\n",
    "        *   **Step 5:** Call `save_news_to_markdown` with the filename `ai_research_report.md` and the \n",
    "            formatted Markdown content.\n",
    "\n",
    "    2.  **After `save_news_to_markdown` succeeds, your final response to the user MUST be:** \"All done. \n",
    "        I've compiled the research report with the latest financial context and saved it to `ai_research_report.md`.\"\n",
    "\n",
    "    **Required Report Schema:**\n",
    "    ```markdown\n",
    "    # AI Industry News Report\n",
    "\n",
    "    ## Top Headlines\n",
    "\n",
    "    ### 1. {News Headline 1}\n",
    "    *   **Company:** {Company Name} ({Ticker Symbol})\n",
    "    *   **Market Data:** {Stock Price and % Change from get_financial_context}\n",
    "    *   **Summary:** {Brief, 1-2 sentence summary of the news.}\n",
    "    *   **Process Log:** {`process_log`: A list of strings describing the filtering actions performed, \n",
    "        including which domains were sourced.}\n",
    "\n",
    "    (Continue for all news items)\n",
    "    ```\n",
    "\n",
    "    **Understanding Callback-Modified Tool Outputs:**\n",
    "    The `google_search` tool is enhanced by pre- and post-processing callbacks. \n",
    "    Its final output is a JSON object with two keys:\n",
    "    1.  `search_results`: A string containing the actual search results.\n",
    "    2.  `process_log`: A list of strings describing the filtering actions performed, including which domains were sourced.\n",
    "\n",
    "    **Callback System Awareness:**\n",
    "    You have a before tool callback \"filter_news_sources_callback\" that will automatically intercepts or \n",
    "    blocks your tool calls. Ensure you call it before each tool.\n",
    "\n",
    "    **When Testing Callbacks:**\n",
    "    If users ask you to test the callback system, be conversational and explain what's happening:\n",
    "    - Acknowledge when callbacks modify your search queries\n",
    "    - Describe the policy enforcement you observe\n",
    "    - Help users understand how the layered control system works in practice\n",
    "\n",
    "    **Crucial Operational Rule:**\n",
    "    Do NOT show any intermediate content (raw search results, draft summaries, or processing steps) in your responses. \n",
    "    Your entire operation is a background pipeline that should culminate in a single, clean final answer.  \n",
    "    \"\"\",\n",
    "    before_tool_callback=[\n",
    "        filter_news_sources_callback,         # Exclude certain domains\n",
    "    ],\n",
    "    after_tool_callback=[\n",
    "        inject_process_log_after_search,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a13459-1c8a-4aa1-9f77-2f578e20c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/5\", \n",
    "       width=600, height=768)\n",
    "\n",
    "# cd L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2c132-6fdd-4a7f-ae50-d26eb02a78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get('DLAI_LOCAL_URL').format(port='8001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2642973-7f0f-4279-82ba-4fbd20ab51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Read and display the markdown file\n",
    "with open('ai_research_report.md', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7e2c3-48fc-48d7-8e8a-5bb75eab38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate ADK process\n",
    "!pkill -f \"adk web\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
