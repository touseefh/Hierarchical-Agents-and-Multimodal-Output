{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b5fbf-2763-4d79-a732-e148ece6bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-adk>=1.12.0\n",
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f751a39-b7aa-40c4-9d81-3730c0a5ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d05ae-d930-4e35-95de-d379b6e3e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create our expected agent folder \n",
    "# You can explore available option: !adk create --help \n",
    "\n",
    "!adk create --type=code app6 --model gemini-2.0-flash-live-001 --api_key $GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d53ff0-fc2d-4bb9-8c2d-5c8847e2628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app6/agent.py\n",
    "\n",
    "\n",
    "from typing import Dict, List\n",
    "import pathlib\n",
    "import wave\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.tools import google_search, ToolContext\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import yfinance as yf\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class NewsStory(BaseModel):\n",
    "    \"\"\"A single news story with its context.\"\"\"\n",
    "    company: str = Field(description=\"Company name associated with the story (e.g., 'Nvidia', 'OpenAI'). Use 'N/A' if not applicable.\")\n",
    "    ticker: str = Field(description=\"Stock ticker for the company (e.g., 'NVDA'). Use 'N/A' if private or not found.\")\n",
    "    summary: str = Field(description=\"A brief, one-sentence summary of the news story.\")\n",
    "    why_it_matters: str = Field(description=\"A concise explanation of the story's significance or impact.\")\n",
    "    financial_context: str = Field(description=\"Current stock price and change, e.g., '$950.00 (+1.5%)'. Use 'No financial data' if not applicable.\")\n",
    "    source_domain: str = Field(description=\"The source domain of the news, e.g., 'techcrunch.com'.\")\n",
    "    process_log: str = Field(description=\"populate the `process_log` field in the schema with the `process_log` list from the `google_search` tool's output.\" ) \n",
    "\n",
    "class AINewsReport(BaseModel):\n",
    "    \"\"\"A structured report of the latest AI news.\"\"\"\n",
    "    title: str = Field(default=\"AI Research Report\", description=\"The main title of the report.\")\n",
    "    report_summary: str = Field(description=\"A brief, high-level summary of the key findings in the report.\")\n",
    "    stories: List[NewsStory] = Field(description=\"A list of the individual news stories found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d94fd-0252-4478-b577-dacaa8fdd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "\n",
    "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
    "    \"\"\"Helper function to save audio data as a wave file\"\"\"\n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(sample_width)\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(pcm)\n",
    "        \n",
    "\n",
    "async def generate_podcast_audio(podcast_script: str, tool_context: ToolContext, filename: str = \"'ai_today_podcast\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generates audio from a podcast script using Gemini API and saves it as a WAV file.\n",
    "\n",
    "    Args:\n",
    "        podcast_script: The conversational script to be converted to audio.\n",
    "        tool_context: The ADK tool context.\n",
    "        filename: Base filename for the audio file (without extension).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with status and file information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = genai.Client()\n",
    "        prompt = f\"TTS the following conversation between Joe and Jane:\\n\\n{podcast_script}\"\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-tts\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_modalities=[\"AUDIO\"],\n",
    "                speech_config=types.SpeechConfig(\n",
    "                    multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(\n",
    "                        speaker_voice_configs=[\n",
    "                            types.SpeakerVoiceConfig(speaker='Joe', \n",
    "                                                     voice_config=types.VoiceConfig(prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name='Kore'))),\n",
    "                            types.SpeakerVoiceConfig(speaker='Jane', \n",
    "                                                     voice_config=types.VoiceConfig(prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name='Puck')))\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        data = response.candidates[0].content.parts[0].inline_data.data\n",
    "\n",
    "        if not filename.endswith(\".wav\"):\n",
    "            filename += \".wav\"\n",
    "\n",
    "        # ** BUG FIX **: This logic now runs for all cases, not just when the extension is added.\n",
    "        current_directory = pathlib.Path.cwd()\n",
    "        file_path = current_directory / filename\n",
    "        wave_file(str(file_path), data)\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Successfully generated and saved podcast audio to {file_path.resolve()}\",\n",
    "            \"file_path\": str(file_path.resolve()),\n",
    "            \"file_size\": len(data)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:200]\n",
    "        return {\"status\": \"error\", \"message\": f\"Audio generation failed: {error_msg}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f5e5f-948a-4771-a40a-efabfc861ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "def get_financial_context(tickers: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fetches the current stock price and daily change for a list of stock tickers.\n",
    "    \"\"\"\n",
    "    financial_data: Dict[str, str] = {}\n",
    "\n",
    "    # Filter out invalid tickers upfront\n",
    "    valid_tickers = [ticker.upper().strip() for ticker in tickers \n",
    "                    if ticker and ticker.upper() not in ['N/A', 'NA', '']]\n",
    "    \n",
    "    if not valid_tickers:\n",
    "        return {ticker: \"No financial data\" for ticker in tickers}\n",
    "        \n",
    "    for ticker_symbol in valid_tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker_symbol)\n",
    "            info = stock.info\n",
    "            price = info.get(\"currentPrice\") or info.get(\"regularMarketPrice\")\n",
    "            change_percent = info.get(\"regularMarketChangePercent\")\n",
    "            \n",
    "            if price is not None and change_percent is not None:\n",
    "                change_str = f\"{change_percent * 100:+.2f}%\"\n",
    "                financial_data[ticker_symbol] = f\"${price:.2f} ({change_str})\"\n",
    "            else:\n",
    "                financial_data[ticker_symbol] = \"Price data not available.\"\n",
    "        except Exception:\n",
    "            financial_data[ticker_symbol] = \"Invalid Ticker or Data Error\"\n",
    "            \n",
    "    return financial_data\n",
    "\n",
    "def save_news_to_markdown(filename: str, content: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Saves the given content to a Markdown file in the current directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not filename.endswith(\".md\"):\n",
    "            filename += \".md\"\n",
    "        current_directory = pathlib.Path.cwd()\n",
    "        file_path = current_directory / filename\n",
    "        file_path.write_text(content, encoding=\"utf-8\")\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Successfully saved news to {file_path.resolve()}\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Failed to save file: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f17fe7-d9b8-4cb2-a7e1-332a5210f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "WHITELIST_DOMAINS = [\"techcrunch.com\", \"venturebeat.com\", \"theverge.com\", \"technologyreview.com\", \"arstechnica.com\"]\n",
    "\n",
    "def filter_news_sources_callback(tool, args, tool_context):\n",
    "    \"\"\"Callback to enforce that google_search queries only use whitelisted domains.\"\"\"\n",
    "    if tool.name == \"google_search\":\n",
    "        original_query = args.get(\"query\", \"\")\n",
    "        if any(f\"site:{domain}\" in original_query.lower() for domain in WHITELIST_DOMAINS):\n",
    "            return None\n",
    "        whitelist_query_part = \" OR \".join([f\"site:{domain}\" for domain in WHITELIST_DOMAINS])\n",
    "        args['query'] = f\"{original_query} {whitelist_query_part}\"\n",
    "        print(f\"MODIFIED query to enforce whitelist: '{args['query']}'\")\n",
    "    return None\n",
    "\n",
    "def enforce_data_freshness_callback(tool, args, tool_context):\n",
    "    \"\"\"Callback to add a time filter to search queries to get recent news.\"\"\"\n",
    "    if tool.name == \"google_search\":\n",
    "        query = args.get(\"query\", \"\")\n",
    "        # Adds a Google search parameter to filter results from the last week.\n",
    "        if \"tbs=qdr:w\" not in query:\n",
    "            args['query'] = f\"{query} tbs=qdr:w\"\n",
    "            print(f\"MODIFIED query for freshness: '{args['query']}'\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af51e80-ede0-4d21-808a-83d7b03a7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "def initialize_process_log(tool_context: ToolContext):\n",
    "    \"\"\"Helper to ensure the process_log list exists in the state.\"\"\"\n",
    "    if 'process_log' not in tool_context.state:\n",
    "        tool_context.state['process_log'] = []\n",
    "\n",
    "def inject_process_log_after_search(tool, args, tool_context, tool_response):\n",
    "    \"\"\"\n",
    "    Callback: After a successful search, this injects the process_log into the response\n",
    "    and adds a specific note about which domains were sourced. This makes the callbacks'\n",
    "    actions visible to the LLM.\n",
    "    \"\"\"\n",
    "    if tool.name == \"google_search\" and isinstance(tool_response, str):\n",
    "        # Extract source domains from the search results\n",
    "        urls = re.findall(r'https?://[^\\s/]+', tool_response)\n",
    "        unique_domains = sorted(list(set(urlparse(url).netloc for url in urls)))\n",
    "        \n",
    "        if unique_domains:\n",
    "            sourcing_log = f\"Action: Sourced news from the following domains: {', '.join(unique_domains)}.\"\n",
    "            # Prepend the new log to the existing one for better readability in the report\n",
    "            current_log = tool_context.state.get('process_log', [])\n",
    "            tool_context.state['process_log'] = [sourcing_log] + current_log\n",
    "\n",
    "        final_log = tool_context.state.get('process_log', [])\n",
    "        print(f\"CALLBACK LOG: Injecting process log into tool response: {final_log}\")\n",
    "        return {\n",
    "            \"search_results\": tool_response,\n",
    "            \"process_log\": final_log\n",
    "        }\n",
    "    return tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d97d0-095e-47b9-97e0-799ffea20386",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "podcaster_agent = Agent(\n",
    "    name=\"podcaster_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"\"\"\n",
    "    You are an Audio Generation Specialist. Your single task is to take a provided text script\n",
    "    and convert it into a multi-speaker audio file using the `generate_podcast_audio` tool.\n",
    "\n",
    "    Workflow:\n",
    "    1. Receive the text script from the user or another agent.\n",
    "    2. Immediately call the `generate_podcast_audio` tool with the provided script and the filename of 'ai_today_podcast'\n",
    "    3. Report the result of the audio generation back to the user.\n",
    "    \"\"\",\n",
    "    tools=[generate_podcast_audio],\n",
    ")\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"ai_news_researcher\",\n",
    "    model=\"gemini-2.0-flash-live-001\", \n",
    "    instruction=\"\"\"\n",
    "    **Your Core Identity:**\n",
    "    You are an AI News Podcast Producer. Your job is to orchestrate a complete workflow: find the latest AI news for US-listed companies on the NASDAQ, compile a report, write a script, and generate a podcast audio file, all while keeping the user informed.\n",
    "\n",
    "    **Crucial Rules:**\n",
    "    1.  **Resilience is Key:** If you encounter an error or cannot find specific information for one item (like fetching a stock ticker), you MUST NOT halt the entire process. Use a placeholder value like \"Not Available\", and continue to the next step. Your primary goal is to deliver the final report and podcast, even if some data points are missing.\n",
    "    2.  **Scope Limitation:** Your research is strictly limited to US-listed companies on the NASDAQ exchange. All search queries and analysis must adhere to this constraint.\n",
    "    3.  **User-Facing Communication:** Your interaction has only two user-facing messages: the initial acknowledgment and the final confirmation. All complex work must happen silently in the background between these two messages.\n",
    "\n",
    "    **Understanding Callback-Modified Tool Outputs:**\n",
    "    The `google_search` tool is enhanced by callbacks. Its final output is a JSON object with two keys:\n",
    "    1.  `search_results`: A string containing the actual search results.\n",
    "    2.  `process_log`: A list of strings describing the filtering actions performed.\n",
    "\n",
    "    **Required Conversational Workflow:**\n",
    "    1.  **Acknowledge and Inform:** The VERY FIRST thing you do is respond to the user with: \"Okay, I'll start researching the latest AI news for NASDAQ-listed US companies. I will enrich the findings with financial data where available and compile a report for you. This might take a moment.\"\n",
    "    2.  **Search (Background Step):** Immediately after acknowledging, use the `google_search` tool to find relevant news. Your query must be specifically tailored to find news about \"AI\" and \"NASDAQ-listed US companies\".\n",
    "    3.  **Analyze & Extract Tickers (Internal Step):** Process search results to identify company names and their stock tickers. If a company is not on NASDAQ or a ticker cannot be found, use 'N/A'.\n",
    "    4.  **Get Financial Data (Background Step):** Call the `get_financial_context` tool with the extracted tickers. If the tool returns \"Not Available\" for any ticker, you will accept this and proceed. Do not stop or report an error.\n",
    "    5.  **Structure the Report (Internal Step):** Use the `AINewsReport` schema to structure all gathered information. If financial data was not found for a story, you MUST use \"Not Available\" in the `financial_context` field. You MUST also populate the `process_log` field in the schema with the `process_log` list from the `google_search` tool's output.\n",
    "    6.  **Format for Markdown (Internal Step):** Convert the structured `AINewsReport` data into a well-formatted Markdown string. This MUST include a section at the end called \"## Data Sourcing Notes\" where you list the items from the `process_log`.\n",
    "    7.  **Save the Report (Background Step):** Save the Markdown string using `save_news_to_markdown` with the filename `ai_research_report.md`.\n",
    "    8.  **Create Podcast Script (Internal Step):** After saving the report, you MUST convert the structured `AINewsReport` data into a natural, conversational podcast script between two hosts, 'Joe' (enthusiastic) and 'Jane' (analytical).\n",
    "    9.  **Generate Audio (Background Step):** Call the `podcaster_agent` tool, passing the complete conversational script you just created to it.\n",
    "    10. **Final Confirmation:** After the audio is successfully generated, your final response to the user MUST be: \"All done. I've compiled the research report, saved it to `ai_research_report.md`, and generated the podcast audio file for you.\"\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        google_search,\n",
    "        get_financial_context,\n",
    "        save_news_to_markdown,\n",
    "        AgentTool(agent=podcaster_agent) \n",
    "    ],\n",
    "    output_schema=AINewsReport,\n",
    "    before_tool_callback=[\n",
    "        filter_news_sources_callback,\n",
    "        enforce_data_freshness_callback,\n",
    "    ],\n",
    "    after_tool_callback=[\n",
    "        inject_process_log_after_search,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b56fc-cb73-47ac-8b8f-50e762c46e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/6\", \n",
    "       width=600, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e4f8c-d04e-4d34-91dd-1fe30880b650",
   "metadata": {},
   "source": [
    "### Getting your application URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc6100-3e7c-4a63-8249-447a913febcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get('DLAI_LOCAL_URL').format(port='8001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a03ea922467fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Read and display the markdown file\n",
    "with open('ai_research_report.md', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04942c5-b411-42b7-9f7c-33dda45e3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Create an audio player that starts automatically\n",
    "Audio('ai_today_podcast.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80444e6-4a03-4580-8ff1-5510ef907a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate ADK process\n",
    "!pkill -f \"adk web\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
